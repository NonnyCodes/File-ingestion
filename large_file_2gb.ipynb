{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRQsYZHQh5j5",
        "outputId": "6e771083-c295-49c2-ec61-91f88d7d026e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating chunk 1 of 9\n",
            "Generating chunk 2 of 9\n",
            "Generating chunk 3 of 9\n",
            "Generating chunk 4 of 9\n",
            "Generating chunk 5 of 9\n",
            "Generating chunk 6 of 9\n",
            "Generating chunk 7 of 9\n",
            "Generating chunk 8 of 9\n",
            "Generating chunk 9 of 9\n",
            "Larger employee churn dataset created and saved as 'employee_churn_large_2gb.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define chunk size and total rows\n",
        "chunk_size = 5_000_000  # 5 million rows per chunk\n",
        "num_chunks = 9  # Create 9 chunks to get 45 million rows in total\n",
        "\n",
        "# Open the CSV file in write mode initially\n",
        "with open('employee_churn_large_2gb.csv', 'w') as f:\n",
        "    for chunk in range(num_chunks):\n",
        "        print(f\"Generating chunk {chunk + 1} of {num_chunks}\")\n",
        "\n",
        "        # Generate random employee churn data for the chunk\n",
        "        data = {\n",
        "            'Employee_ID': np.arange(chunk * chunk_size + 1, (chunk + 1) * chunk_size + 1),  # Unique Employee ID\n",
        "            'Age': np.random.randint(22, 65, size=chunk_size),\n",
        "            'Gender': np.random.choice(['Male', 'Female'], size=chunk_size),\n",
        "            'Years_At_Company': np.random.randint(1, 35, size=chunk_size),\n",
        "            'Last_Promotion': np.random.randint(0, 10, size=chunk_size),\n",
        "            'Salary': np.random.randint(30_000, 200_000, size=chunk_size),\n",
        "            'Ethnicity': np.random.choice(['White', 'Black', 'Asian', 'Hispanic', 'Other'], size=chunk_size),\n",
        "            'Department': np.random.choice(['Sales', 'IT', 'HR', 'Marketing', 'Finance', 'Operations'], size=chunk_size),\n",
        "            'Number_of_Projects': np.random.randint(1, 10, size=chunk_size),\n",
        "            'Work_Life_Balance_Score': np.random.randint(1, 5, size=chunk_size),\n",
        "            'Job_Satisfaction_Score': np.random.randint(1, 5, size=chunk_size),\n",
        "            'left': np.random.choice([0, 1], size=chunk_size)\n",
        "        }\n",
        "\n",
        "        # Create the DataFrame for the chunk\n",
        "        df_chunk = pd.DataFrame(data)\n",
        "\n",
        "        # Write header only for the first chunk, otherwise append without header\n",
        "        if chunk == 0:\n",
        "            df_chunk.to_csv(f, index=False, header=True)\n",
        "        else:\n",
        "            df_chunk.to_csv(f, index=False, header=False, mode='a')\n",
        "\n",
        "print(\"Larger employee churn dataset created and saved as 'employee_churn_large_2gb.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check the size of the created CSV file in GB\n",
        "file_size = os.path.getsize('employee_churn_large_2gb.csv') / (1024 ** 3)  # Convert to GB\n",
        "print(f\"File size: {file_size:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_yHoX8jIb-",
        "outputId": "a20a92f2-95c1-4300-ad79-405cb75daf6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 2.12 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZID5sOWpjMA2",
        "outputId": "93ba655d-5b2e-4ecb-e355-5b067a0c2381"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2024.7.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.20.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import time\n",
        "\n",
        "# Measure time taken to read the CSV file using Dask\n",
        "start_time = time.time()\n",
        "\n",
        "# Dask reads the CSV in parallel without loading everything into memory\n",
        "df_dask = pd.read_csv('employee_churn_large_2gb.csv')\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Dask read time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Now let's inspect the shape (number of rows and columns)\n",
        "# We need to \"compute\" the result since Dask works lazily\n",
        "rows = df_dask.shape[0].compute()\n",
        "columns = df_dask.shape[1]\n",
        "\n",
        "print(f\"Shape of the dataframe: {rows} rows, {columns} columns\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZwOTMz2kKzk",
        "outputId": "f7e0f857-1a9f-4d7b-cc41-847261eed325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modin[ray] ray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkYX-G69ktvd",
        "outputId": "7ace4f2b-1298-4f0c-aafe-39d8ecda47ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting modin[ray]\n",
            "  Downloading modin-0.32.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pandas<2.3,>=2.2 (from modin[ray])\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (24.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (1.26.4)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (2024.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (14.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2024.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->modin[ray]) (1.16.0)\n",
            "Downloading ray-2.35.0-cp310-cp310-manylinux2014_x86_64.whl (65.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modin-0.32.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, modin, ray\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed modin-0.32.0 pandas-2.2.2 ray-2.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_hA3VkdlRVp",
        "outputId": "51c0d6e6-ec3c-4739-b34e-5fbe5d3342eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pandas -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLw-tdNfmol3",
        "outputId": "eaa4e000-d86d-4499-a3f4-202938ade704"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.2.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5cqvudrmxl7",
        "outputId": "8471e69a-95f5-4f31-9e4a-cf3db8b9f3ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
            "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modin[ray] ray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ7vBajFnDUv",
        "outputId": "1f853839-0c45-4a83-fcf3-c7880db25fbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.35.0)\n",
            "Requirement already satisfied: modin[ray] in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (2.2.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (24.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (1.26.4)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (2024.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from modin[ray]) (14.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[ray]) (2024.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->modin[ray]) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import modin.pandas as mpd\n",
        "import time\n",
        "\n",
        "# Measure time taken by Modin (on Ray) to read the large CSV file\n",
        "start_time = time.time()\n",
        "\n",
        "# Modin will parallelize the loading process\n",
        "df_modin = mpd.read_csv('employee_churn_large_2gb.csv')\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Modin read time: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Shape of the dataframe: {df_modin.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qS-z4jdnISg",
        "outputId": "050cbdb9-97b4-4f0e-e6a0-7f5a117154d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: The size of /dev/shm is too small (6133121024 bytes). The required size at least half of RAM (6804715520 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can can override the memory size for each Ray worker (in bytes) to the MODIN_MEMORY environment variable.\n",
            "2024-09-14 22:20:37,621\tINFO worker.py:1783 -- Started a local Ray instance.\n",
            "\u001b[33m(raylet)\u001b[0m [2024-09-14 22:22:37,536 E 6728 6728] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c84c994dd496b0f46cc3caa8392b83679f6973f7bd8fa83a0dbaebaa, IP: 172.28.0.12) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.28.0.12`\n",
            "\u001b[33m(raylet)\u001b[0m \n",
            "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modin read time: 208.17 seconds\n",
            "Shape of the dataframe: (45000000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Define the chunk size\n",
        "chunk_size = 1_000_000  # 1 million rows at a time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize an empty list to store the chunks\n",
        "chunks = []\n",
        "\n",
        "# Read the file in chunks and append them to the list\n",
        "for chunk in pd.read_csv('employee_churn_large_2gb.csv', chunksize=chunk_size):\n",
        "    chunks.append(chunk)\n",
        "\n",
        "# Concatenate all chunks into a single DataFrame (optional)\n",
        "df_pandas = pd.concat(chunks, axis=0)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Pandas (with chunking) read time: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Shape of the dataframe: {df_pandas.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4AV8Y-ApXSb",
        "outputId": "c61503cf-3cf4-42d5-d319-cffee552c0bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas (with chunking) read time: 72.63 seconds\n",
            "Shape of the dataframe: (45000000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean column names by removing special characters and white spaces\n",
        "df_dask.columns = df_dask.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True).str.strip()\n",
        "\n",
        "# Verify the cleaned column names\n",
        "print(\"Cleaned column names:\", df_dask.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbTYHqCPqMNy",
        "outputId": "d68606ce-e58a-4a00-f0d6-088bc48b91f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned column names: ['Employee_ID', 'Age', 'Gender', 'Years_At_Company', 'Last_Promotion', 'Salary', 'Ethnicity', 'Department', 'Number_of_Projects', 'Work_Life_Balance_Score', 'Job_Satisfaction_Score', 'left']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQ8XpSKZt2ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Read the CSV file using Dask\n",
        "df_dask = dd.read_csv('employee_churn_large_2gb.csv')\n",
        "\n",
        "# Print a few rows to verify\n",
        "print(df_dask.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "076y4BfYtGRq",
        "outputId": "4e715e91-8c12-4cab-a18b-973daf8ddbc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Employee_ID  Age  Gender  Years_At_Company  Last_Promotion  Salary  \\\n",
            "0            1   60    Male                 3               6   96346   \n",
            "1            2   50  Female                 6               3   54229   \n",
            "2            3   36  Female                32               7  166233   \n",
            "3            4   64  Female                34               9   88052   \n",
            "4            5   29  Female                28               3  109972   \n",
            "\n",
            "  Ethnicity  Department  Number_of_Projects  Work_Life_Balance_Score  \\\n",
            "0     White          IT                   8                        1   \n",
            "1     Black  Operations                   4                        3   \n",
            "2     Other     Finance                   6                        2   \n",
            "3     Other  Operations                   1                        4   \n",
            "4     White          IT                   4                        1   \n",
            "\n",
            "   Job_Satisfaction_Score  left  \n",
            "0                       3     0  \n",
            "1                       4     1  \n",
            "2                       2     0  \n",
            "3                       3     1  \n",
            "4                       4     1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc1bRV_At5eZ",
        "outputId": "edbe1837-b7b4-45d5-b092-b0fa977b9daa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define the schema and file details\n",
        "schema = {\n",
        "    'file_name': 'employee_churn_large_2gb.csv',\n",
        "    'separator': ',',\n",
        "    'columns': df_dask.columns.tolist()\n",
        "}\n",
        "\n",
        "# Save the schema to a YAML file\n",
        "with open('schema.yml', 'w') as yaml_file:\n",
        "    yaml.dump(schema, yaml_file)\n",
        "\n",
        "print(\"YAML schema file created as 'schema.yml'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNH1KuYDuFMW",
        "outputId": "8984573c-1f0d-4743-9262-1eb433e852b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML schema file created as 'schema.yml'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the schema from the YAML file\n",
        "with open('schema.yml', 'r') as yaml_file:\n",
        "    yaml_schema = yaml.safe_load(yaml_file)\n",
        "\n",
        "# Extract column names from the YAML file\n",
        "yaml_columns = yaml_schema['columns']\n",
        "\n",
        "# Validate if the columns in the dataframe match the columns in the YAML\n",
        "if list(df_dask.columns) == yaml_columns:\n",
        "    print(\"Column validation passed.\")\n",
        "else:\n",
        "    print(\"Column validation failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW0VFe33uTRh",
        "outputId": "b6b45199-d738-474d-a506-adc0449dee82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column validation passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the DataFrame to a pipe-separated CSV file and compress it\n",
        "df_dask.to_csv('employee_churn_large_pipe_*.csv', sep='|', index=False, compression='gzip', single_file=True)\n",
        "\n",
        "print(\"File written in pipe-separated format and compressed as 'employee_churn_large_pipe.gz'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6qgK2bTuinY",
        "outputId": "b3124e9b-1435-4f8b-e970-f7fcbff7c083"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File written in pipe-separated format and compressed as 'employee_churn_large_pipe.gz'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Compute the number of rows in the Dask DataFrame\n",
        "total_rows = df_dask.shape[0].compute()\n",
        "total_columns = df_dask.shape[1]\n",
        "\n",
        "# Get the file size of the compressed file\n",
        "file_size = os.path.getsize('employee_churn_large_pipe_*.csv') / (1024 ** 3)  # Convert to GB\n",
        "\n",
        "# Print the summary\n",
        "print(f\"Total rows: {total_rows}\")\n",
        "print(f\"Total columns: {total_columns}\")\n",
        "print(f\"File size: {file_size:.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZzoRIEMyLAX",
        "outputId": "d449d08d-6845-45ac-ee94-d3225d4734f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 45000000\n",
            "Total columns: 12\n",
            "File size: 0.55 GB\n"
          ]
        }
      ]
    }
  ]
}